<!DOCTYPE html>
<html lang="en-us">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <meta property="og:site_name" content="Kaster Mist Blog">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="http://localhost:1313//img/home-bg-jeep.jpg">
    <meta property="twitter:image" content="http://localhost:1313//img/home-bg-jeep.jpg" />
    

    
    <meta name="title" content="CUDA学习(七)" />
    <meta property="og:title" content="CUDA学习(七)" />
    <meta property="twitter:title" content="CUDA学习(七)" />
    

    
    <meta name="description" content="">
    <meta property="og:description" content="" />
    <meta property="twitter:description" content="" />
    

    
    <meta property="twitter:card" content="summary" />
    
    

    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>CUDA学习(七) | 喀斯特雾霭的博客 | Kaster Mist Blog</title>

    <link rel="canonical" href="/post/cuda%E5%AD%A6%E4%B9%A0-%E4%B8%83/">

    
    
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/css/hugo-theme-cleanwhite.min.css">

    
    <link rel="stylesheet" href="/css/zanshang.css">

    
    <link rel="stylesheet" href="/css/font-awesome.all.min.css">

    
    

    
    <script src="/js/jquery.min.js"></script>

    
    <script src="/js/bootstrap.min.js"></script>

    
    <script src="/js/hux-blog.min.js"></script>

    
    <script src="/js/lazysizes.min.js"></script>

    
    

</head>






<nav class="navbar navbar-default navbar-custom navbar-fixed-top">

    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Kaster Mist Blog</a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">All Posts</a>
                    </li>
                    
                        
                        <li>
                            <a href="/categories/cuda/">cuda</a>
                        </li>
                        
                        <li>
                            <a href="/categories/unix/">unix</a>
                        </li>
                        
                    
                    
		    
                        <li><a href="/archive//">ARCHIVE</a></li>
                    
                        <li><a href="/notes//">NOTES</a></li>
                    
                        <li><a href="/about//">ABOUT</a></li>
                    
		            <li>
                        <a href="/search"><i class="fa fa-search"></i></a>
		           </li>
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>




<style type="text/css">
    header.intro-header {
        background-image: url('/img/home-bg-jeep.jpg')
    }
</style>

<header class="intro-header" >

    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                    </div>
                    <h1>CUDA学习(七)</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                        
                            Posted by 
                            
                                    Kaster Mist Blog
                             
                            on 
                            Wednesday, February 28, 2024
                            
                            
                            
                            
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>




<article>
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                
                <p>在并行环境中，任务可以是任意操作。例如，应用程序可以执行两个任务：其中一个线程重绘程序的GUI，而另一个线程通过网络下载更新包。这些任务并行执行，彼此之间没有任何共同的地方。虽然GPU上的任务并行性并不像CPU上的任务并行性那样灵活，但仍然可以进一步提高程序在GPU上的运行速度。本章将介绍CUDA流，以及如何通过流在GPU上同时执行多个任务。</p>
<!-- raw HTML omitted -->
<h2 id="页锁定page-locked主机内存">页锁定(Page-Locked)主机内存</h2>
<p>CUDA提供了自己独有的机制来分配主机内存：cudaHostAlloc()。malloc()分配的内存与cudaHostAlloc()分配的内存之间存在一个重要差异。C库函数malloc()将分配标准的、可分页的(Pagable)主机内存，而cudaHostAlloc()将分配页锁定的主机内存。页锁定内存也称为固定内存(Pinned Memory)或者不可分页内存，它有一个重要属性：操作系统将不会对这块内存分页并交还到磁盘上，从而确保了该内存始终驻留在物理内存中。因此，操作系统能够安全地使某个应用程序访问该内存的物理地址，因为这块内存将不会被破坏或者重新定位。</p>
<p>由于GPU知道内存的物理地址，因此可以通过“直接内存访问（Direct Memory Access，DMA）”技术来在GPU和主机之间复制数据。由于DMA在执行复制时无需CPU的介入，这也就意味着，CPU很可能在DMA的执行过程中将目标内存交换到磁盘上，或者通过更新操作系统的分页来重新定位目标内存的物理地址。CPU可能会移动可分页的数据，这就可能对DMA操作造成延迟。因此，在DMA复制过程中使用固定内存时非常重要的。</p>
<p>事实上，当使用可分页内存进行复制时，CUDA驱动程序仍然会通过DAM把数据传输给GPU。因此，复制操作将执行两遍，第一遍从可分页内存复制到一块“临时的”页锁定内存，然后再从这个页锁定内存复制到GPU上。因此，**每当从可分页内存中执行复制操作时，复制速度将受限于PCIE（高速串行计算机扩展总线标准）传输速度和系统前端总线速度相对较低的一方。当在GPU和主机间复制数据时，这种差异会使页锁定主机内存的性能比标准可分页内存的性能要高达约2倍。**计时PCIE的速度与前端总线的速度相等，由于可分页内存需要更多一次由CPU参与的复制操作，因此会带来额外的开销。</p>
<p>然而，使用cudaHostAlloc()分配固定内存时，将失去虚拟内存的所有功能。特别是在应用程序中使用每个页锁定内存时都需要分配物理内存，因为这些内存不能交换到磁盘上。这意味着与使用标准的malloc()调用相比，系统将更快地耗尽内存。因此，应用程序在物理内存较少的机器上会运行失败，而且意味着应用程序将影响在系统上运行的其他应用程序的性能。建议仅对cudaMemcpy()调用中的源内存或者目标内存才使用页锁定内存，并且在不再需要使用它们时立即释放，而不是等到应用程序关闭时才释放。</p>
<p>下面给的例子来说明如何分配固定内存，以及它相对于标准可分页内存的性能优势。这个例子主要是测试cudaMemcpy()在可分配内存和页锁定内存上的性能。我们要做的就是分配一个GPU缓冲区以及一个大小相等的主机缓冲区，然后两个缓冲区之间执行一些复制操作（从主机到设备、从设备到主机）。为了获得精确的时间统计，我们为复制操作的起始时刻和结束时刻分别设置了CUDA事件。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#8be9fd">float</span> <span style="color:#50fa7b">cuda_malloc_test</span>(<span style="color:#8be9fd">int</span> size, <span style="color:#8be9fd">bool</span> up){
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">cudaEvent_t</span> start, stop;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>a, <span style="color:#ff79c6">*</span>dev_a;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">float</span> elapsedTime;
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventCreate</span>(<span style="color:#ff79c6">&amp;</span>start));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventCreate</span>(<span style="color:#ff79c6">&amp;</span>stop));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    a <span style="color:#ff79c6">=</span> (<span style="color:#8be9fd">int</span><span style="color:#ff79c6">*</span>)<span style="color:#50fa7b">malloc</span>(size <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#ff79c6">*</span>a));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_NULL</span>(a);
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_a, size <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#ff79c6">&amp;</span>dev_a)));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cuddaEventRecord</span>(start, <span style="color:#bd93f9">0</span>));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//为size个整数分别分配主机缓冲区和GPU缓冲区，然后执行100次复制操作，并由参数up来指定复制方向，在完成复制操作后停止计时器
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#ff79c6">for</span>(<span style="color:#8be9fd">int</span> i <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>; i <span style="color:#ff79c6">&lt;</span> <span style="color:#bd93f9">100</span>; i<span style="color:#ff79c6">++</span>){
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">if</span>(up){
</span></span><span style="display:flex;"><span>            <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpy</span>(dev_a, a, size <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#ff79c6">*</span>dev_a), cudaMemcpyHostToDevice));
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">else</span>{
</span></span><span style="display:flex;"><span>            <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpy</span>(a, dev_a, size <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#ff79c6">*</span>dev_a), cudaMemcpyDeviceToHost));
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventRecord</span>(stop, <span style="color:#bd93f9">0</span>));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventSynchronize</span>(stop));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventElapsedTime</span>(<span style="color:#ff79c6">&amp;</span>elapsedTime, start, stop));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">free</span>(a);
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_a));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventDestroy</span>(start));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventDestroy</span>(stop));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> elapsedTime;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>函数cuda_malloc_test()通过标准的C函数malloc()来分配可分页主机内存，在分配固定内存时则使用了cudaHostAlloc()。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#8be9fd">float</span> <span style="color:#50fa7b">cuda_host_alloc_test</span>(<span style="color:#8be9fd">int</span> size, <span style="color:#8be9fd">bool</span> up){
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">cudaEvent_t</span> start, stop;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>a, <span style="color:#ff79c6">*</span>dev_a;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">float</span> elapsedTime;
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventCreate</span>(<span style="color:#ff79c6">&amp;</span>start));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventCreate</span>(<span style="color:#ff79c6">&amp;</span>stop));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaHostAlloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>a, size <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#ff79c6">*</span>a), cudaHostAllocDefault));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_a, size <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#ff79c6">*</span>dev_a)));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventRecord</span>(start, <span style="color:#bd93f9">0</span>));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span>(<span style="color:#8be9fd">int</span> i <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>; i <span style="color:#ff79c6">&lt;</span> <span style="color:#bd93f9">100</span>; i<span style="color:#ff79c6">++</span>){
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">if</span>(up){
</span></span><span style="display:flex;"><span>            <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpy</span>(dev_a, a, size <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#ff79c6">*</span>dev_a), cudaMemcpyHostToDevice));
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">else</span>{
</span></span><span style="display:flex;"><span>            <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpy</span>(a, dev_a, size <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#ff79c6">*</span>dev_a), cudaMemcpyDeviceToHost));
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventRecord</span>(stop, <span style="color:#bd93f9">0</span>));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventSynchronize</span>(stop));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventElapsedTime</span>(<span style="color:#ff79c6">&amp;</span>elapsedTime, start, stop));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFreeHost</span>(a));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_a));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventDestroy</span>(start));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventDestroy</span>(stop));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> elapsedTime;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>cudaHostAlloc()分配的内存与malloc()分配的内存在使用方式是相同的，与malloc()不同之处在于最后一个参数cudaHostAllocDefault。最后一个参数的取值范围是一组标志，我们可以通过这些标志来修改cudaHostAlloc()的行为，并分配不同形式的固定主机内存。就目前而言，只需使用默认值。最后需要使用cudaFreeHost()来释放内存。</p>
<p>main()函数的代码如下：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#ff79c6">#include</span> <span style="color:#ff79c6">&#34;../common/book.h&#34;</span><span style="color:#ff79c6">
</span></span></span><span style="display:flex;"><span><span style="color:#ff79c6"></span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#define SIZE (10 * 1024 * 1024)
</span></span></span><span style="display:flex;"><span><span style="color:#ff79c6"></span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd">int</span> <span style="color:#50fa7b">main</span>(){
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">float</span> elapsedTime;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">float</span> MB <span style="color:#ff79c6">=</span> (<span style="color:#8be9fd">float</span>)<span style="color:#bd93f9">100</span> <span style="color:#ff79c6">*</span> SIZE <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>) <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">1024</span> <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">1024</span>;
</span></span><span style="display:flex;"><span>    elapsedTime <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">cuda_malloc_test</span>(SIZE, <span style="color:#8be9fd;font-style:italic">true</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;Time using cudaMalloc: %3.1fms</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>, elapsedTime);
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;</span><span style="color:#f1fa8c">\t</span><span style="color:#f1fa8c">MB/s during copy up: %3.1f</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>, MB <span style="color:#ff79c6">/</span> (elapsedTime <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">1000</span>));
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//要执行相反方向的性能，可以执行相同的调用，只需要将第二个参数指定为false
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    elapsedTime <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">cuda_malloc_test</span>(SIZI, <span style="color:#8be9fd;font-style:italic">false</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;Time using cudaMalloc: %3.1f ms </span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>, elapsedTime);
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;</span><span style="color:#f1fa8c">\t</span><span style="color:#f1fa8c">MB/s during copy down: %3.1f</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>, MB <span style="color:#ff79c6">/</span> (elapsedTime <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">1000</span>));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//测试cudaHostAlloc()的性能
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    elapsedTime <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">cuda_host_malloc_test</span>(SIZE, <span style="color:#8be9fd;font-style:italic">true</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;Time using cudaHostMalloc: %3.1fms</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>, elapsedTime);
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;</span><span style="color:#f1fa8c">\t</span><span style="color:#f1fa8c">MB/s during copy up: %3.1f</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>, MB <span style="color:#ff79c6">/</span> (elapsedTime <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">1000</span>));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    elapsedTime <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">cuda_host_malloc_test</span>(SIZI, <span style="color:#8be9fd;font-style:italic">false</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;Time using cudaHostMalloc: %3.1f ms </span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>, elapsedTime);
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;</span><span style="color:#f1fa8c">\t</span><span style="color:#f1fa8c">MB/s during copy down: %3.1f</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>, MB <span style="color:#ff79c6">/</span> (elapsedTime <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">1000</span>));
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="cuda流">CUDA流</h2>
<p>之前介绍过cudaEventRecord()，并没有详细解释这个函数的第二个参数，这个第二个参数是用于指定插入事件的流(Stream)。CUDA流表示一个GPU操作队列，并且该队列中的操作将以指定的顺序执行。我们可以在流中添加一些操作，例如核函数启动、内存复制，以及时间的启动和结束等。你可以将每个流视为GPU上的一个任务，并且这些任务可以并行执行。我们将首先介绍如何使用流，然后介绍如何使用流来加速应用程序。</p>
<h3 id="使用单个cuda流">使用单个CUDA流</h3>
<p>仅当使用多个流时才能显现出流的真正威力。不过我们先用一个流来说明用法。下面的示例中，我们将计算a中三个值和b中三个值的平均值。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#ff79c6">#include</span> <span style="color:#ff79c6">&#34;../common/book.h&#34;</span><span style="color:#ff79c6">
</span></span></span><span style="display:flex;"><span><span style="color:#ff79c6"></span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#define N (1024 * 1024)
</span></span></span><span style="display:flex;"><span><span style="color:#ff79c6">#define FULL_DATA_SIZE (N * 20)
</span></span></span><span style="display:flex;"><span><span style="color:#ff79c6"></span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#8be9fd">void</span> <span style="color:#50fa7b">kernel</span>(<span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>a, <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>b, <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>c){
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">int</span> idx <span style="color:#ff79c6">=</span> threadIdx.x <span style="color:#ff79c6">+</span> blockIdx.x <span style="color:#ff79c6">*</span> blockDim.x;
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">if</span>(idx <span style="color:#ff79c6">&lt;</span> N){
</span></span><span style="display:flex;"><span>        <span style="color:#8be9fd">int</span> idx1 <span style="color:#ff79c6">=</span> (idx <span style="color:#ff79c6">+</span> <span style="color:#bd93f9">1</span>) <span style="color:#ff79c6">%</span> <span style="color:#bd93f9">256</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#8be9fd">int</span> idx2 <span style="color:#ff79c6">=</span> (idx <span style="color:#ff79c6">+</span> <span style="color:#bd93f9">2</span>) <span style="color:#ff79c6">%</span> <span style="color:#bd93f9">256</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#8be9fd">float</span> as <span style="color:#ff79c6">=</span> (a[idx] <span style="color:#ff79c6">+</span> a[idx1] <span style="color:#ff79c6">+</span> a[idx2]) <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">3.0f</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#8be9fd">float</span> bs <span style="color:#ff79c6">=</span> (b[idx] <span style="color:#ff79c6">+</span> b[idx1] <span style="color:#ff79c6">+</span> b[idx2]) <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">3.0f</span>;
</span></span><span style="display:flex;"><span>        c[idx] <span style="color:#ff79c6">=</span> (as <span style="color:#ff79c6">+</span> bs) <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">2</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd">int</span> <span style="color:#50fa7b">main</span>(){
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//选择一个一个支持设备重叠功能的设备。支持设备重叠功能的GPU能够在执行一个CUDA C核函数的同时，
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#6272a4">//还能在设备与主机之间执行复制操作。	
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    cudaDeviceProp prop;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">int</span> whichDevice;
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaGetDevice</span>(<span style="color:#ff79c6">&amp;</span>whichDevice));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaGetDeviceProperties</span>(<span style="color:#ff79c6">&amp;</span>prop, whichDevice));
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">if</span>(<span style="color:#ff79c6">!</span>prop.deviceOverlap){
</span></span><span style="display:flex;"><span>        <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;Device will not handle overlaps, so no speed up from streams</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">cudaEvent_t</span> start, stop;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">float</span> elapsedTime;
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//启动计时器
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventCreate</span>(<span style="color:#ff79c6">&amp;</span>start));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventCreate</span>(<span style="color:#ff79c6">&amp;</span>stop));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventRecord</span>(start, <span style="color:#bd93f9">0</span>));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//初始化流
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#8be9fd">cudaStream_t</span> stream;
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaStreamCreate</span>(<span style="color:#ff79c6">&amp;</span>stream));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//数据分配操作
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>host_a, <span style="color:#ff79c6">*</span>host_b, <span style="color:#ff79c6">*</span>host_c;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>dev_a, <span style="color:#ff79c6">*</span>dev_b, <span style="color:#ff79c6">*</span>dev_c;
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//在GPU上分配内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_a, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>)));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_b, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>)));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_c, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>)));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//分配由流使用的页锁定内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaHostAlloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>host_a, FULL_DATA_SIZE <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaHostAllocDefault));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaHostAlloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>host_b, FULL_DATA_SIZE <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaHostAllocDefault));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaHostAlloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>host_c, FULL_DATA_SIZE <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaHostAllocDefault));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span>(<span style="color:#8be9fd">int</span> i <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>; i <span style="color:#ff79c6">&lt;</span> FULL_DATA_SIZE; i<span style="color:#ff79c6">++</span>){
</span></span><span style="display:flex;"><span>        host_a[i] <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">rand</span>();
</span></span><span style="display:flex;"><span>        host_b[i] <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">rand</span>();
</span></span><span style="display:flex;"><span>    }
</span></span></code></pre></div><p>程序将使用主机上的固定内存。我们还会使用一种新的cudaMemcpy()函数，并且在这个新函数中需要页锁定主机内存。在分配完输入内存后，调用C的库函数rand()并用随机证书填充主机内存。</p>
<p>执行计算的方式是将两个输入缓冲区复制到GPU，启动核函数，然后将输出缓冲区复制回主机。不过，本示例做出了小的调整。首先，我们不将输入缓冲区整体都复制到GPU，而是将输入缓冲区划分为更小的块，并在每个块上执行一个包含三个步骤的过程。我们将一部分输入缓冲区复制到GPU，在这部分缓冲区上运行核函数，然后将输出缓冲区的这部分结果复制回主机。下面给出了一个需要这种方法的情形：GPU的内存远少于主机内存，由于整个缓冲区无法一次性填充到GPU，因此需要分块进行计算。执行“分块”计算的代码如下所示：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>    <span style="color:#6272a4">//在整体数据上循环，每个数据块的大小为N
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#ff79c6">for</span>(<span style="color:#8be9fd">int</span> i <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>; i <span style="color:#ff79c6">&lt;</span> FULL_DATA_SIZE; i <span style="color:#ff79c6">+=</span> N){
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4">//将锁定内存以异步的方式复制到设备上
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>        <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(dev_a, host_a <span style="color:#ff79c6">+</span> i, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyHostToDevice, stream));
</span></span><span style="display:flex;"><span>        <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(dev_b, host_b <span style="color:#ff79c6">+</span> i, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyHostToDevice, stream));
</span></span><span style="display:flex;"><span>        kernel<span style="color:#ff79c6">&lt;&lt;&lt;</span>N <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">256</span>, <span style="color:#bd93f9">256</span>, <span style="color:#bd93f9">0</span>, stream<span style="color:#ff79c6">&gt;&gt;&gt;</span>(dev_a, dev_b, dev_c);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4">//将数据从设备复制到锁定内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>        <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(host_c <span style="color:#ff79c6">+</span> i, dev_c, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyDeviceToHost. stream));
</span></span><span style="display:flex;"><span>	}
</span></span></code></pre></div><p>上述代码使用cudaMemcpyAsync()在GPU与主机之间复制数据。cudaMemcpy()的行为类似于C库函数memcpy()，尤其是这个函数将以同步的方式进行。这意味着当函数返回时，复制操作就已经完成，并且在输出缓冲区中包含了复制进去的内容。异步函数的行为与同步函数相反，在调用cudaMemcpyAsync()时，只是放置一个请求，表示在流中执行一次内存复制操作，这个流时通过参数stream来指定的。当函数返回时，我们无法确保复制操作是否已经启动，更无法保证它是否已经结束。**我们能够得到的保证是，复制操作肯定会将肯定会当下一个被放入流中的操作之前执行。**任何传递给cudaMemcpyAsync()的主机内存指针都必须已经通过cudaHostAlloc()分配好内存。也就是，<strong>你只能以异步方式对页锁定内存进行复制操作。</strong></p>
<p>在核函数调用的尖括号中还可以带有一个流参数。此时核函数调用将是异步的。从技术上来说，当循环迭代完一次时，有可能不会启动任何内存复制或核函数执行。<strong>我们能够确保的是，第一次放入流中的复制操作将在第二次复制操作之前执行。此外，第二个复制操作将在核函数启动之前完成。而核函数将在第三次复制操作开始之前完成。</strong></p>
<p>当for循环结束时，在队列中应该包含了许多等待GPU执行的工作。如果想要确保GPU执行完了计算和内存复制等操作，那么就需要将GPU与主机同步。也就是说，主机在继续执行之前，要首先等待GPU执行完成。可以调用cudaStreamSynchronize()并制定想要等待的流。当程序执行到stream与主机同步之后的代码时，所有的计算和复制操作都已经完成，因此停止计时器，收集性能数据，并释放输入缓冲区和输出缓冲区。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>    <span style="color:#6272a4">//将计算结果从页锁定内存复制到主机内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaStreamSynchronize</span>(stream));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventRecord</span>(stop, <span style="color:#bd93f9">0</span>));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventSynchronize</span>(stop));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventElapsedTime</span>(<span style="color:#ff79c6">&amp;</span>elapsedTime, start, stop));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;Time taken: 3.1%f ms</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>, elapsedTime);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//释放流和内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFreeHost</span>(host_a));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFreeHost</span>(host_b));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFreeHost</span>(host_c));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_a));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_b));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_c));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//销毁对GPU操作进行排队的流
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaStreamDestroy</span>(stream));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="使用多个cuda流">使用多个CUDA流</h3>
<p>我们将上面的示例改为使用两个不同的流。我们将实现：在第0个流执行核函数的同时，第1个流将输入缓冲区复制到GPU。然后在第0个流将计算结果复制回主机的同时，第1个流将执行核函数。接着，第1个流将计算结果复制回主机，同时第0个流开始在下一块数据上执行核函数。假设内存复制操作和核函数执行的事件大致相同，那么应用程序的执行时间线将如图下所示（后续图片中函数调用cudaMemcpyAsync()被简写为复制）：</p>
<p>
  <img src="imgs/CUDA_7_1.png" alt="CUDA_7_1">

</p>
<p>核函数的代码保持不变。与使用单个流的版本一样，我们将判断设备是否支持计算与内存复制操作的重叠。如果设备支持重叠，那么就像前面一样创建CUDA事件并对应用程序计时。创建两个流的方式与之前代码中创建单个流的方式是一样的。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#ff79c6">#include</span> <span style="color:#ff79c6">&#34;../common/book.h&#34;</span><span style="color:#ff79c6">
</span></span></span><span style="display:flex;"><span><span style="color:#ff79c6"></span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">#define N (1024 * 1024)
</span></span></span><span style="display:flex;"><span><span style="color:#ff79c6">#define FULL_DATA_SIZE (N * 20)
</span></span></span><span style="display:flex;"><span><span style="color:#ff79c6"></span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#8be9fd">void</span> <span style="color:#50fa7b">kernel</span>(<span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>a, <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>b, <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>c){
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">int</span> idx <span style="color:#ff79c6">=</span> threadIdx.x <span style="color:#ff79c6">+</span> blockIdx.x <span style="color:#ff79c6">*</span> blockDim.x;
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">if</span>(idx <span style="color:#ff79c6">&lt;</span> N){
</span></span><span style="display:flex;"><span>        <span style="color:#8be9fd">int</span> idx1 <span style="color:#ff79c6">=</span> (idx <span style="color:#ff79c6">+</span> <span style="color:#bd93f9">1</span>) <span style="color:#ff79c6">%</span> <span style="color:#bd93f9">256</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#8be9fd">int</span> idx2 <span style="color:#ff79c6">=</span> (idx <span style="color:#ff79c6">+</span> <span style="color:#bd93f9">2</span>) <span style="color:#ff79c6">%</span> <span style="color:#bd93f9">256</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#8be9fd">float</span> as <span style="color:#ff79c6">=</span> (a[idx] <span style="color:#ff79c6">+</span> a[idx1] <span style="color:#ff79c6">+</span> a[idx2]) <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">3.0f</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#8be9fd">float</span> bs <span style="color:#ff79c6">=</span> (b[idx] <span style="color:#ff79c6">+</span> b[idx1] <span style="color:#ff79c6">+</span> b[idx2]) <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">3.0f</span>;
</span></span><span style="display:flex;"><span>        c[idx] <span style="color:#ff79c6">=</span> (as <span style="color:#ff79c6">+</span> bs) <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">2</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8be9fd">int</span> <span style="color:#50fa7b">main</span>(){
</span></span><span style="display:flex;"><span>    cudaDeviceProp prop;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">int</span> whichDevice;
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaGetDevice</span>(<span style="color:#ff79c6">&amp;</span>whichDevice));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaGetDeviceProperties</span>(<span style="color:#ff79c6">&amp;</span>prop, whichDevice));
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">if</span>(<span style="color:#ff79c6">!</span>prop.deviceOverlap){
</span></span><span style="display:flex;"><span>        <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;Device will not handle overlaps, so no speed up from streams</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">cudaEvent_t</span> start, stop;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">float</span> elapsedTime;
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//启动计时器
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventCreate</span>(<span style="color:#ff79c6">&amp;</span>start));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventCreate</span>(<span style="color:#ff79c6">&amp;</span>stop));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventRecord</span>(start, <span style="color:#bd93f9">0</span>));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//初始化流
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#8be9fd">cudaStream_t</span> stream0, stream1;
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaStreamCreate</span>(<span style="color:#ff79c6">&amp;</span>stream0));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaStreamCreate</span>(<span style="color:#ff79c6">&amp;</span>stream1));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//数据分配操作
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>host_a, <span style="color:#ff79c6">*</span>host_b, <span style="color:#ff79c6">*</span>host_c;
</span></span><span style="display:flex;"><span>    <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>dev_a0, <span style="color:#ff79c6">*</span>dev_b0, <span style="color:#ff79c6">*</span>dev_c0; <span style="color:#6272a4">//为第0个流分配的GPU内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#8be9fd">int</span> <span style="color:#ff79c6">*</span>dev_a1, <span style="color:#ff79c6">*</span>dev_b1, <span style="color:#ff79c6">*</span>dev_c1; <span style="color:#6272a4">//为第1个流分配的GPU内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//在GPU上分配内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_a0, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>)));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_b0, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>)));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_c0, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>)));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_a1, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>)));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_b1, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>)));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMalloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>dev_c1, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>)));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//分配由流使用的页锁定内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaHostAlloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>host_a, FULL_DATA_SIZE <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaHostAllocDefault));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaHostAlloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>host_b, FULL_DATA_SIZE <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaHostAllocDefault));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaHostAlloc</span>((<span style="color:#8be9fd">void</span><span style="color:#ff79c6">**</span>)<span style="color:#ff79c6">&amp;</span>host_c, FULL_DATA_SIZE <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaHostAllocDefault));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span>(<span style="color:#8be9fd">int</span> i <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>; i <span style="color:#ff79c6">&lt;</span> FULL_DATA_SIZE; i<span style="color:#ff79c6">++</span>){
</span></span><span style="display:flex;"><span>        host_a[i] <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">rand</span>();
</span></span><span style="display:flex;"><span>        host_b[i] <span style="color:#ff79c6">=</span> <span style="color:#50fa7b">rand</span>();
</span></span><span style="display:flex;"><span>    }
</span></span></code></pre></div><p>之后，程序在输入数据块上循环。然而，由于现在使用了两个流，因此在for()循环的迭代中需要处理的数据量也是原来的两倍。在stream()中，我们首先将a和b的异步复制操作放入GPU的队列，然后将一个核函数执行放入队列，接下来再将一个复制回c的操作放入队列：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>    <span style="color:#6272a4">//在整体数据上循环，每个数据块的大小为N
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#ff79c6">for</span>(<span style="color:#8be9fd">int</span> i <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>; i <span style="color:#ff79c6">&lt;</span> FULL_DATA_SIZE; i <span style="color:#ff79c6">+=</span> N <span style="color:#ff79c6">*</span> <span style="color:#bd93f9">2</span>){
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4">//将锁定内存以异步方式复制到设备上
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>        <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(dev_a0, host_a <span style="color:#ff79c6">+</span> i, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyHostToDevice, stream0));
</span></span><span style="display:flex;"><span>        <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(dev_b0, host_b <span style="color:#ff79c6">+</span> i, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyHostToDevice, stream0));
</span></span><span style="display:flex;"><span>        kernel<span style="color:#ff79c6">&lt;&lt;&lt;</span>N <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">256</span>, <span style="color:#bd93f9">256</span>, <span style="color:#bd93f9">0</span>, stream0<span style="color:#ff79c6">&gt;&gt;&gt;</span>(dev_a0, dev_b0, dev_c0);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4">//将数据从设备复制回锁定内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>        <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(host_c <span style="color:#ff79c6">+</span> i, dev_c0, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyDeviceToHost, stream0));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4">//在将这些操作放入stream0队列后，再把下一个数据块上的相同操作放入stream1的队列中
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4">//将锁定内存以异步方式复制到设备上
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>        <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(dev_a1, host_a <span style="color:#ff79c6">+</span> i <span style="color:#ff79c6">+</span> N, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyHostToDevice, stream1));
</span></span><span style="display:flex;"><span>        <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(dev_b1, host_b <span style="color:#ff79c6">+</span> i <span style="color:#ff79c6">+</span> N, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyHostToDevice, stream1));
</span></span><span style="display:flex;"><span>        kernel<span style="color:#ff79c6">&lt;&lt;&lt;</span>N <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">256</span>, <span style="color:#bd93f9">256</span>, <span style="color:#bd93f9">0</span>, stream1<span style="color:#ff79c6">&gt;&gt;&gt;</span>(dev_a1, dev_b1, dev_c1);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#6272a4">//将数据从设备复制回锁定内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>        <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(host_c <span style="color:#ff79c6">+</span> i <span style="color:#ff79c6">+</span> N, dev_c1, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyDeviceToHost, stream0));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    }
</span></span></code></pre></div><p>这样，在for循环的迭代过程中，将交替地把每个数据块放入这两个流的队列，直到所有待处理的输入数据都被放入队列。在结束了for循环后，在停止应用程序的计时器之前，首先将GPU与GPU进行同步，由于使用了两个流，因此要对二者都进行同步。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span>	<span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaStreamSynchronize</span>(stream0));
</span></span><span style="display:flex;"><span>	<span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaStreamSynchronize</span>(stream1));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventRecord</span>(stop, <span style="color:#bd93f9">0</span>));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventSynchronize</span>(stop));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaEventElapsedTime</span>(<span style="color:#ff79c6">&amp;</span>elapsedTime, start, stop));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">printf</span>(<span style="color:#f1fa8c">&#34;Time taken: 3.1%f ms</span><span style="color:#f1fa8c">\n</span><span style="color:#f1fa8c">&#34;</span>, elapsedTime);
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>	<span style="color:#6272a4">//释放流和内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFreeHost</span>(host_a));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFreeHost</span>(host_b));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFreeHost</span>(host_c));
</span></span><span style="display:flex;"><span>	<span style="color:#6272a4">//销毁两个流，释放两倍的GPU内存
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_a0));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_b0));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_c0));
</span></span><span style="display:flex;"><span>	<span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_a1));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_b1));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaFree</span>(dev_c1));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//销毁对GPU操作进行排队的流
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaStreamDestroy</span>(stream0));
</span></span><span style="display:flex;"><span>	<span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaStreamDestroy</span>(stream1));
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="gpu的工作调度机制">GPU的工作调度机制</h3>
<p>我们可以将流视为有序的操作序列，其中既包含内存复制操作，又包含核函数调用。下图将展示任务调度情形。</p>
<p>
  <img src="imgs/CUDA_7_2.png" alt="CUDA_7_2">

</p>
<p>从图中得到，第0个流对A的内存复制需要在对B的内存复制之前完成，而对B的复制又要在核函数A启动之前完成。然而，一旦这些操作放入到硬件的内存复制引擎和核函数执行引擎的队列中时，这些依赖性将丢失，因此CUDA驱动程序需要确保硬件的执行单元不破坏流内部的依赖性。</p>
<p>从之前的代码中可以得知，应用程序基本上是对a调用一次cudaMemcpyAsync()，对b调用一次cudaMemcpyAsync()，然后再是执行核函数以及调用cudaMemcpyAsync()将c复制回主机。应用程序首先将第0个流的所有操作放入队列，然后是第1个流的所有操作。CUDA驱动程序负责按照这些操作的顺序把他们调度到硬件上执行，这就维持了流内部的依赖性。下图体现了这些依赖性，其中从复制操作到核函数的箭头表示，复制操作要等核函数执行完成之后才能开始。</p>
<p>
  <img src="imgs/CUDA_7_3.png" alt="CUDA_7_3">

</p>
<p>假定理解了GPU的工作调度远离后，我们可以得到关于这些操作在硬件上执行的时间线，如下图所示：</p>
<p>
  <img src="imgs/CUDA_7_4.png" alt="CUDA_7_4">

</p>
<p>由于第0个流中将c复制回主机的操作要等待核函数执行完成，因此第1个流中将a和b复制到GPU的操作虽然是完全独立的，但却被阻塞了，这是因为GPU引擎是按照指定的顺序来执行工作。这种情况很好地说明了为什么在程序中使用了两个流却无法获得加速的窘境。这个问题的直接原因是我们没有意识到硬件的工作方式与CUDA流编程模型的方式是不同的。</p>
<h3 id="高效地使用多个cuda流">高效地使用多个CUDA流</h3>
<p>从上面的说明可以得出，如果同时调度某个流的所有操作，那么很容易在无意中阻塞另一个流的复制操作或者核函数执行。要解决这个问题，在将操作放入流的队列时应采用宽度优先的方式，而非深度优先的方式。<strong>也就是说不是首先添加第0个流的所有四个操作（即a的复制、b的复制、核函数以及c的复制），然后不再添加第1个流的所有四个操作，而是将这两个流之间的操作交叉添加。</strong></p>
<p>首先，将a的复制操作添加到第0个流，然后将a的复制操作添加到第1个流。接着，将b的复制操作添加到第0个流，再将b的复制操作添加到第1个流。接下来，将核函数调用添加到第0个流，再将相同的操作添加到第1个流中。最后，将c的复制操作添加到第0个流中，然后将相同的操作添加到第1个流中。</p>
<p>下面是实际的代码。我们的修改仅限于for循环中的两个流的处理，采用宽度优先方式将操作分配到两个流的代码如下：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#ff79c6">for</span>(<span style="color:#8be9fd">int</span> i <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>; i <span style="color:#ff79c6">&lt;</span> FULL_DATA_SIZE; i <span style="color:#ff79c6">+=</span> N <span style="color:#ff79c6">*</span> <span style="color:#bd93f9">2</span>){
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//将复制a的操作放入stream0和stream1的队列
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(dev_a0, host_a <span style="color:#ff79c6">+</span> i, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyHostToDevice, stream0));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(dev_a1, host_a <span style="color:#ff79c6">+</span> i <span style="color:#ff79c6">+</span> N, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyHostToDevice, stream1));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//将复制b的操作放入stream0和stream1的队列
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(dev_b0, host_b <span style="color:#ff79c6">+</span> i, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyHostToDevice, stream0));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(dev_b1, host_b <span style="color:#ff79c6">+</span> i <span style="color:#ff79c6">+</span> N, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyHostToDevice, stream1));
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//将核函数的执行放入stream0和stream1的队列中
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    kernel<span style="color:#ff79c6">&lt;&lt;&lt;</span>N <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">256</span>, <span style="color:#bd93f9">256</span>, <span style="color:#bd93f9">0</span>, stream0<span style="color:#ff79c6">&gt;&gt;&gt;</span>(dev_a0, dev_b0, dev_c0);
</span></span><span style="display:flex;"><span>    kernel<span style="color:#ff79c6">&lt;&lt;&lt;</span>N <span style="color:#ff79c6">/</span> <span style="color:#bd93f9">256</span>, <span style="color:#bd93f9">256</span>, <span style="color:#bd93f9">0</span>, stream1<span style="color:#ff79c6">&gt;&gt;&gt;</span>(dev_a1, dev_b1, dev_c1);
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#6272a4">//将复制c的操作放入stream0和stream1的队列
</span></span></span><span style="display:flex;"><span><span style="color:#6272a4"></span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(host_c <span style="color:#ff79c6">+</span> i, dev_c0, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyDeviceToHost, stream0));
</span></span><span style="display:flex;"><span>    <span style="color:#50fa7b">HANDLE_ERROR</span>(<span style="color:#50fa7b">cudaMemcpyAsync</span>(host_c <span style="color:#ff79c6">+</span> i <span style="color:#ff79c6">+</span> N, dev_c1, N <span style="color:#ff79c6">*</span> <span style="color:#ff79c6">sizeof</span>(<span style="color:#8be9fd">int</span>), cudaMemcpyDeviceToHost, stream1));
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>此时，新的执行时间线将如下图所示：</p>
<p>
  <img src="imgs/CUDA_7_5.png" alt="CUDA_7_5">

</p>


                

                
                <hr>
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/post/cuda%E5%AD%A6%E4%B9%A0-%E5%85%AD/" data-toggle="tooltip" data-placement="top" title="CUDA学习(六)">&larr;
                            Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/post/cuda%E5%AD%A6%E4%B9%A0-%E5%85%AB/" data-toggle="tooltip" data-placement="top" title="CUDA学习(八)">Next
                            Post &rarr;</a>
                    </li>
                    
                </ul>
                

                



            </div>

            
            
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
            

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                        
                        
                    </div>
                </section>
                

                
                
                <section>
                    <hr>
                    <h5>FRIENDS</h5>
                    <ul class="list-inline">
                        
                        <li><a target="_blank" href=""></a></li>
                        
                    </ul>
                </section>
                
            </div>
        </div>
    </div>
</article>




<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">                  
                    
                    <li>
                        <a href="mailto:KasterMist@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		           
                    
                    
                    
                    

		            
                    
                    
                    <li>
                        <a target="_blank" href="https://github.com/KasterMist">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		            
                    
                    
                    
                    <li>
                        <a target="_blank" href="https://www.linkedin.com/in/letian-xie-8a0886282/">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		           
                    
                    
                    
                    
                    
                    
            
            
            
           
             </ul>
		<p class="copyright text-muted">
                    Copyright &copy; Kaster Mist Blog 2024
                    
                    <br>
                    <a href="https://themes.gohugo.io/hugo-theme-cleanwhite">CleanWhite Hugo Theme</a> by <a href="https://zhaohuabing.com">Huabing</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true" >
                    </iframe>
                    
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function loadAsync(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>






<script>
    
    if($('#tag_cloud').length !== 0){
        loadAsync("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>






<script type="text/javascript">
    function generateCatalog(selector) {

        
        
        
        
            _containerSelector = 'div.post-container'
        

        
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        
        $(selector).html('')

        
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    


    loadAsync("\/js\/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>






</body>
</html>
